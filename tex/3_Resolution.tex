%\section{}
Resolution appeared in the early 1960's through investigations on performance
improvements of refutational systems based on the \emph{Herbrand's Theorem}, which
allows a kind of reduction of first-order logic to propositional
logic~\cite{casanova}. In particular, Prawitz' studies of such systems brought
back the concept of unification. J.\ A.\ Robinson incorporated this concept on a
refutational system, creating what was later known as
resolution~\cite{Robinson65}. 

Resolution relies on saturation. A saturation-based theorem proving is usually
characterized by a process in which new formulae are derived from given ones by
thorough application of specified inference rules. This process keeps producing
information until no new information can be generated. In addition, the current
set of formulae is analyzed to identify the most promising inference rules to be
applied next and to eliminate redundancies~\cite{bachmair2001resolution}.

Numerous resolution systems for propositional logic have been proposed in the
literature~\cite{bachmair2001resolution}. The standard system has only one
inference rule~\cite{Robinson65}, showed in Equation~\ref{eq:res}, that takes
two \emph{clauses} with literals that form a complementary pair and generates a
\emph{resolvent}, where each clause, denoted by $\clause$, is a disjunction of
literals. 

\begin{equation}
\label{eq:res}
 \begin{array}{lc}
     \mbox{[RES]} & \clause_i \lor l \qquad \neg l \lor \clause_j\\  \cline{2-2}
     & \clause_i \lor \clause_j
\end{array}
\end{equation}
where $\clause_i$ and $\clause_j$ are (possibly empty) clauses, $l$ is a literal
and $\clause_i \lor \clause_j$ is the resolvent.

We use the constant $\cfalse$ to denote the \emph{empty clause},
i.e., the clause that contains no literals. Due to the associativity and
commutativity properties of disjunction, one may see a clause as a set of
literals. In this work we might abuse of set notation, writing $l \in \clause$,
when $l$ is a literal of $\clause$, and $\clause_i \subseteq \clause_j$, when
all literals in $\clause_i$ are also literals in $\clause_j$.

A clause set is said to be \emph{saturated} when relevant information can no
longer be generated, regardless of the rule (or set of rules) that is
applied~\cite{dershowitz2003abstract}. Saturation, up to redundancy, of the
initial clause set is a quite useful criteria when we are thinking in terms of
% cite reference to termination 
termination proof and completeness proof~\cite{fitting} of a calculus.

% be specific %
Most of the systems based on the rule of Equation~\ref{eq:res} work exclusively
with clauses in a specific normal form. Resolution, as proposed by Robinson, is
a refutationally complete theorem proving method for first order
logic~\cite{Robinson65}.  Therefore, to show that a formula \formula~is valid,
$\neg \formula$ is translated into a normal form, then the inference rule is
applied until either no new resolvents can be generated or a contradiction is
obtained. This means that the search for a contradiction proceeds by
exhaustively applying the inference rule to the clause
set~\cite{bachmair2001resolution}. The contradiction implies that $\neg
\formula$ is unsatisfiable and hence, that \formula~is valid. 

Resolution-based provers are widely implemented and
tested~\cite{bachmair2001resolution}. Besides reliable implementations, we can
also profit from several complete strategies, as, for instance, \emph{tree-like
resolution}~\cite{satchapter}, \emph{ordered resolution} and
\emph{selection-based resolution}~\cite{de2000resolution}, which can be
extended to deal with modal formulae~\cite{journals/jal/NalonD07}. Such provers
for multimodal logics require pruning of the search space for a proof in order
to deal with the inherent intractability of the satisfiability problem for such
logics.  In~\cite{nalon2015modal}, Nalon et.\ al.\ present a clausal
modal-layered resolution calculus for \system{K}{n}{}, which divides the clause
set according to the modal layer at which each clause occurs. This calculus is
introduced in Section~\ref{sec:calculus}.

\section{Clausal Resolution}

Clausal resolution is a simple and adaptable proof system for classical logics.
It was proposed by Robinson in 1965~\cite{Robinson65}, and was claimed to be
suitable to be performed by a computer, as, for propositional logic, it has only
one inference rule that is applied to the set of clauses. Robinson
emphasizes that, from the theoretical point of view, an inference rule need only
to be sound and effective, that is, it allows only logical consequences of
premisses to be deduced and it must be algorithmically decidable whether an
alleged application of the rule is indeed an application of it.

The single inference rule of this system of logic, given in
Equation~\ref{eq:res}, entails the \emph{resolution principle}, namely:
\emph{From any two clauses} $\clause_i$ \emph{and} $\clause_j$ \emph{which
contain a complementary pair of literals, one may infer a resolvent of}
$\clause_i$ \emph{and} $\clause_j$~\cite{Robinson65}.   

In his paper, Robinson presents a formalization of first-order logic, designed to
be used as the basic theoretical instrument of the proposed computer
theorem-proving program. For the purpose of this work, we are only interested in
the calculus for propositional logic. Therefore, we will neither discuss the theory
behind the Herbrand's Theorem nor the definition of the unification procedure,
but, if curious, the reader can refer to~\cite{Robinson65} for more details.

In the sense of this last remark, the only representational formalism needed is
propositional logic. As resolution has only the RES rule, shown in
Equation~\ref{eq:res}, a proof consists of repeated applications of this rule to
the propositional clauses. These applications are sufficient to derive the empty
clause if and only if the initial formula is unsatisfiable~\cite{satchapter}.

\begin{example}%
\label{ex:res}
    Consider the set of clauses $\Clauses = \{(\neg p \lor q), (\neg p \lor r),
    (\neg r \lor q), (\neg q \lor r), \neg r, p\}$. Figure~\ref{tab:res} shows an
    example of derivation of the empty clause for $\Clauses$, proving that this
    set is unsatisfiable. 

    \begin{figure}%
        \centering
        \begin{tabular}{rlll}
            1. & $\neg p \lor q$ & & \\
            2. & $\neg p \lor r$ & & \\
            3. & $\neg r \lor q$ & & \\
            4. & $\neg q \lor r$ & & \\
            5. & $\neg r$ & & \\
            6. & $p$ & & \\
            7. & $\neg p \lor q$ & [RES,3,2] & $= 1$\\
            8. & $\neg p \lor r$ & [RES,4,1] & $= 2$\\
            9. & $\neg q \lor q$ & [RES,4,3] & $= \ctrue$\\
            10.&  $\neg r \lor r$ & [RES,4,3] & $= \ctrue$\\
            11.&  $\neg p$ & [RES,5,2] & \\
            12.&  $\neg q$ & [RES,5,4] & \\
            13.&  $q$ & [RES,6,1] & \\
            14.&  $r$ & [RES,6,2] & \\
            15.&  $\cfalse$ & [RES,11,6] & contradiction\\
        \end{tabular}%
    \caption{Derivation of $\Clauses$ in Example~\ref{ex:res}}%
    \label{tab:res}
    \end{figure}

    Despite its simplicity, unrestricted resolution is hard to implement
    efficiently due to the difficulty of finding good choices of clauses to
    resolve~\cite{satchapter}. As one can infer from this example, a raw
    implementation of resolution-based systems typically implies huge storage
    requirements. Even with such a short set of clauses (only 6 initially), the
    application of the resolution rule, without any restriction, yields the
    generation of tautologies, Clauses 9 and 10, and repeated clauses, Clauses 7
    and 8. That is, useless information is generated and stored until the
    contradiction can be found. 
\end{example}

Robinson established two principles, namely \emph{purity principle} and
\emph{subsumption principle}, to discuss the question of developing efficient
resolution systems. Such principles are called \emph{search principles}. A third
search principle is presented in terms of replacement using the subsumption
principle, named, \emph{replacement principle}. 

\begin{definition}
    If $\Clauses$ is any finite set of clauses, $\clause$ is a clause in
    $\Clauses$ and $l$ a literal in $\clause$ with the property that no literal
    in any other clause in $\Clauses$ form a complementary pair with $l$, then
    $l$ is said to be \emph{pure} in $\Clauses$.
\end{definition}

The purity principle is then based on Theorem~\ref{theo:pure}.

\begin{theorem}%
    \label{theo:pure}
    If $\Clauses$ is any finite set of clauses, and $l \in \clause \in \Clauses$
    is a pure literal in $\Clauses$, then $\Clauses$ is satisfiable if and only
    if $\Clauses - \{\clause\}$ is satisfiable.
\end{theorem}

\begin{definition}
    If $\clause_i$ and $\clause_j$ are two distinct nonempty clauses, we say
    that $\clause_i$ \emph{subsumes} $\clause_j$ in the case that $\clause_i
    \subseteq \clause_j$. 
\end{definition}

Theorem~\ref{theo:subs} establishes the basic property of subsumption.

\begin{theorem}%
    \label{theo:subs}
    If $\Clauses$ is any finite set of clauses, and $\clause_j$ is any clause
    in $\Clauses$ which is subsumed by some clause in $\Clauses -
    \{\clause_j\}$, then $\Clauses$ is satisfiable if and only if $\Clauses -
    \{\clause_j\}$ is satisfiable.
\end{theorem}

Theorems~\ref{theo:pure} and~\ref{theo:subs} are both proved in~\cite{Robinson65}.

A particularly useful application of the subsumption principle is the following:
suppose a resolvent $\clause_R$ of $\clause_i$ and $\clause_j$ subsumes
$\clause_i$, then in adding $\clause_R$ as a result of resolving $\clause_i$ and
$\clause_j$, we may simultaneously delete, by the subsumption principle,
$\clause_i$. This combined operation entails the replacement of $\clause_i$ by
$\clause_R$; accordingly this third principle is named as the
replacement principle.

The application, to a finite set $\Clauses$ of clauses, of any of the three
search principles described, produces a set $\Clauses'$ which either has fewer
clauses than $\Clauses$ or has the same number, but with one or more shorter
clauses~\cite{Robinson65}. An obvious method of exploiting these principles in a
refutation procedure is therefore never to apply the resolution principle,
generating new clauses, except to a set to which the three principles are no
longer applicable. 

\begin{example}
    Let $\Clauses$ be the set of clauses showed in Figure~\ref{tab:resa}. Prior
    to the thorough application of the RES rule, one may search for
    opportunities to apply the search principles, in order to reduce the
    number and size of clauses.

    In this example, the third clause can be eliminated from the set of clauses
    through an application of the purity principle, as expressed in
    Figure~\ref{tab:resb}, because there is no other clause that has the
    complementary pair of the literal $u$. 
    Furthermore, as the Clause 5 subsumes the Clause 4, this last one can also
    be eliminated from the set of clauses, leaving only the clauses in
    Figure~\ref{tab:resc}.
    The application of RES to Clauses 1 and 2 generates the resolvent
    $\neg q$, which subsumes both clauses, hence, by the self-subsumption principle,
    both may be replaced by the Clause 7, as showed in Figure~\ref{tab:resd}.
    Finally, the application of RES to the Clauses 5 and 7, generates the Clause
    8 as a resolvent, and then resolving this one with the Clause 6 will
    generate the empty clause, thus, a contradiction. 

    Applying the search principles, proposed by Robinson, allowed us to go from
    a set of six clauses with four literals to a set of four clauses with only
    two.

    \begin{figure}
        \centering
       \begin{subfigure}{.20\textwidth}
           \caption{Initial clauses}
           \begin{tabular}{rl}
               1. & $\neg q \lor \neg r$ \\
               2. & $\neg q \lor r$ \\
               3. & $u \lor \neg p$ \\
               4. & $\neg p \lor q \lor \neg r$ \\
               5. & $\neg p \lor q$ \\
               6. & $p$
           \end{tabular}%
           \label{tab:resa}
       \end{subfigure} 
       \begin{subfigure}{.21\textwidth}
           \caption{Purity principle}
           \begin{tabular}{rl}
               1. & $\neg q \lor \neg r$ \\
               2. & $\neg q \lor r$ \\
               4. & $\neg p \lor q \lor \neg r$ \\
               5. & $\neg p \lor q$ \\
               6. & $p$ \\
                  & 
           \end{tabular}%
           \label{tab:resb}
       \end{subfigure} 
       \begin{subfigure}{.19\textwidth}
           \caption{Subsumption}
           \begin{tabular}{rl}
               1. & $\neg q \lor \neg r$ \\
               2. & $\neg q \lor r$ \\
               5. & $\neg p \lor q$ \\
               6. & $p$ \\
                  & \\
                  &
           \end{tabular}%
           \label{tab:resc}
       \end{subfigure} 
       \begin{subfigure}{.24\textwidth}
           \caption{Replacement}
           \begin{tabular}{rll}
               5. & $\neg p \lor q$ \\
               6. & $p$ \\
               7. & $\neg q$ & [RES,1,2] \\
               8. & $\neg p$ & [RES,5,7] \\
               9.& $\cfalse$ & [RES,6,8] \\
                  &
           \end{tabular}%
           \label{tab:resd}
       \end{subfigure} 
        \caption{Derivation schemes for Example~\ref{ex:principles}}
    \end{figure}%
\label{ex:principles}
\end{example}

There are further principles of the same general sort, possibly less simple than
the ones presented earlier, which Robinson considers to be merely a brief view
of the possible approaches to the efficiency problem of resolution systems.
Details can be found in~\cite{Robinson65}.

\section{Modal-Layered Resolution Calculus for \system{K}{n}{}}%
\label{sec:calculus}

The calculus presented in this section requires a translation into a more
expressive modal language, presented in Section~\ref{sec:snf}, where labels are
used to express semantic properties of a formula. This calculus uses 
labelled resolution in order to avoid unnecessary applications of the inference
rules~\cite{nalon2015modal}. For instance, we do not apply resolution to clauses
at different modal levels, since they are not, in fact, contradictory.

\subsection{Separated Normal Form with Modal Levels}%
\label{sec:snf}

Formulae in \system{K}{n}{} can be transformed into a layered normal form called
\emph{Separated Normal Form with Modal Levels}, denoted by \snf{$ml$}, proposed
in~\cite{journals/jal/NalonD07}, hence, all the definitions in this section are
taken from~\cite{journals/jal/NalonD07}. A formula in \snf{$ml$} is a
conjunction of \emph{clauses} where the modal level in which they occur is made
explicit in the syntax as a label.

We write $ml: \formula$ to denote that \formula~occurs at modal level $ml\in
\Nat \cup \{*\}$. By $*: \formula$ we mean that \formula~is true at
all modal levels. Formally, let $\wffml$ denote the set of formulae with
the modal level annotation, $ml : \formula$, such that $ml \in \Nat \cup \{*\}$
and $\formula \in \wff$. Let $\Model^* = (W, \st_0, R_1, \ldots, R_n, R_*, \pi)$
be a tree-like model and take $\formula \in \wff$. 

\begin{definition}
Satisfiability of labelled formulae is given by:

\begin{enumerate}
    \item $\Model^* \models_L ml : \formula$ if, and only if, for all worlds
        $\st \in W$ such that $depth(\st) = ml$, we have
        \sat{\Model^*}{\st}{\formula};
    \item $\Model^* \models_L * : \formula$ if, and only if, $\Model^* \models
        \nec{*} \formula$.
\end{enumerate}
    
\end{definition}

Clauses in \snf{$ml$} are defined as follows.

\begin{definition}
    Clauses in \snf{$ml$} are in one of the following forms:
    \begin{enumerate}
        \item Literal clause $\ \ \quad \qquad ml : \bigvee^r_{b=1} l_b$
        \item Positive $a$-clause $\ \qquad ml : l' \then \nec{a} l$
        \item Negative $a$-clause $\qquad ml : l' \then \pos{a} l$
    \end{enumerate}
    where $r, b \in \Nat, ml \in \Nat \cup \{*\}$, $l, l', l_b \in
    \Literals$ and $\agent \in \Agents = \{1, \ldots, n\}$.
\end{definition}

Positive and negative $a$-clauses are together known as \emph{modal
$a$-clauses}. The index $a$ can be omitted if it is clear from the context.

The transformation of a formula $\formula \in \wff$ into \snf{$ml$} is achieved
by first transforming $\formula$ into its \emph{Negation Normal Form}, and then,
recursively applying rewriting and renaming~\cite{plaisted1986structure}.

\begin{definition}
    Let $\formula \in \wff$. We say that $\formula$ is in Negation Normal Form (NNF) if
    it contains only the operators $\neg, \lor, \land, \nec{a}$ and $\pos{a}$. Also,
    only propositions are allowed in the scope of negations.
\end{definition}

Let $\formula$ be a formula and $t$ a propositional symbol not occurring in
$\formula$. The translation of $\formula$ is given by $0 : t \land \rho(0 : t
\then \formula)$ --- for global satisfiability, the translation is given by $* :
t \land \rho(* : t \then \formula)$ --- where $\rho$ is the \emph{translation
function} defined below. We refer as \emph{initial clauses} the literals clauses
at the modal level 0. 

\begin{definition}
    The translation function $\rho : \wffml \longrightarrow \wffml$ is defined
    as follows:
        \begin{align*}
            \rho(ml : t \then \formula \land \psi) & = \rho(ml : t \then \formula) \land \rho(ml : t \then \psi) \\
            \rho(ml : t \then \nec{a} \formula) & = (ml : t \then \nec{a} \formula) \text{, if \formula\ is a literal}\\
                                                & = (ml : t \then \nec{a} t') \land \rho(ml+1 : t' \then \formula) \text{, otherwise}\\
            \rho(ml : t \then \pos{a} \formula) & = (ml : t \then \pos{a} \formula) \text{, if \formula\ is a literal}\\
                                                & = (ml : t \then \pos{a} t') \land \rho(ml+1 : t' \then \formula) \text{, otherwise}\\
            \rho(ml : t \then \formula \lor \psi) & = (ml : \neg t \lor \formula
            \lor \psi) \text{, if $\psi$ is a disjunction of literals}\\
                                                  & = \rho(ml : t \then \formula \lor t') \land \rho(ml : t' \then \psi) \text{, otherwise}
        \end{align*}
        Where $t, t' \in \Literals$, $\formula, \psi \in \wff$, $ml \in
        \Nat \cup \{*\}$ and $r, b \in \Nat$.
\end{definition}

As the conjunction operator is commutative, associative and idempotent, we will
commonly refer to a formula in \snf{$ml$} as a set of clauses.

\begin{example}%
    \label{ex:snf}
    Let $\formula$ be the formula $\nec{}(a \then b) \then (\nec{}a \then \nec{} b)$.
    We show how to translate $\formula$ into its normal form, considering the local
    satisfiability problem.

    First, we anchor the NNF of $\formula$ to the initial state:
    \begin{equation}
        \label{eq:initial}
        0 : t_0 \land \rho(0 : t_0 \then \pos{} (a \land \neg b) \lor \pos{} \neg a \lor \nec{} b)
    \end{equation}

    The Equation~\ref{eq:initial} is used to anchor the meaning of $\formula$ to
    the initial state, where the formula is evaluated. The function $\rho$
    proceeds with the translation, replacing complex formulae inside the
    scope of the $\nec{}$ and $\pos{}$ operators, by means of renaming. 

    So the translation proceeds as follows:
    \begin{align*}
        &\rho(0 : t_0 \then \pos{} (a \land \neg b) \lor \pos{} \neg a \lor \nec{} b) \\
        &= \rho(0: t_0 \then \pos{} (a \land \neg b) \lor t_1) \land \rho(0: t_1 \then \pos{} \neg a \lor \nec{} b) \\
        &= \rho(0: t_0 \then t_2 \lor t_1) \land \rho(0 : t_2 \then \pos {}(a \land \neg b)) \land \rho(0: t_1 \then \pos{} \neg a \lor t_3) \land \rho(0: t_3 \then \nec{} b) \\
        &= (0: \neg t_0 \lor t_2 \lor t_1) \land (0 : t_2 \then \pos {}t_4) \land \rho(1 : t_4 \then a \land \neg b) \land \rho(0: t_1 \then t_5 \lor t_3) \land \\
        &\ (0 : t_5 \then \pos{} \neg a) \land (0: t_3 \then \nec{} b) \\
        &= (0: \neg t_0 \lor t_2 \lor t_1) \land (0 : t_2 \then \pos {}t_4)
        \land \rho(1 : t_4 \then a) \land \rho(1 : t_4 \then \neg b) \land \\ 
        &\ (0: \neg t_1 \lor t_5 \lor t_3) \land (0 : t_5 \then \pos{} \neg a) \land (0: t_3 \then \nec{} b) \\
        &= (0: \neg t_0 \lor t_2 \lor t_1) \land (0 : t_2 \then \pos {}t_4)
        \land (1 : \neg t_4 \lor a) \land (1 : \neg t_4 \lor \neg b) \land \\ 
        &\ (0: \neg t_1 \lor t_5 \lor t_3) \land (0 : t_5 \then \pos{} \neg a) \land (0: t_3 \then \nec{} b) \\
    \end{align*}

    The translation generates eight clauses, two of them at the subsequent modal
    level ($1 : \neg t_4 \lor a$ and $1 : \neg t_4 \lor \neg b$). Note that,
    from the six clauses at the initial modal level, we have three literal
    clauses ($0: t_0$, $0: \neg t_0 \lor t_2 \lor t_1$ and $0: \neg t_1 \lor t_5
    \lor t_3$), known as the initial clauses, two negative clauses ($0 : t_2
    \then \pos {}t_4$ and $0 : t_5 \then \pos{} \neg a$) and one positive clause
    ($0: t_3 \then \nec{} b$).
\end{example}

The set of clauses obtained by translating the formula $\formula$ into
\snf{$ml$}, from Example~\ref{ex:snf}, must be locally satisfiable if, and only
if, $\formula$ is locally satisfiable. The next lemma, taken
from~\cite{nalon2015modal}, states that the transformation into \snf{$ml$}
preserves satisfiability.

\begin{lemma}
    Let $\formula \in \wff$ be a formula and let $t$ be a propositional symbol
    not occurring in $\formula$. Then: 
    \begin{enumerate}
        \item[$(i)$] $\formula$ is locally satisfiable if, and only if, $0 : t \land \rho(0 : t \then \formula)$ is satisfiable;
        \item[$(ii)$] $\formula$ is globally satisfiable if, and only if, $* : t \land \rho(* : t \then \formula)$ is satisfiable.
    \end{enumerate}
\end{lemma}

\subsection{Calculus}

The motivation for the use of this labelled clausal normal form in a calculus is
that inference rules can then be guided by the semantic information given by the
labels and applied to smaller sets of clauses, reducing the number of
unnecessary applications of the inference rules, and therefore improving the efficiency of the proof
procedure~\cite{Nalon2016}. 

The modal-layered resolution calculus, proposed by Nalon et.\ al.\
in~\cite{nalon2015modal}, comprises a set of inference rules, given in
Table~\ref{rules}, for dealing with propositional and modal reasoning. In the
following, we denote by $\sigma$ the result of unifying the labels in the
premises for each rule.  Formally, unification is given by a function $ \sigma :
\mathscr{P}(\Nat \cup \{*\}) \longrightarrow \Nat \cup \{*\}$, where $\sigma
(\{ml, *\}) = ml$ and $\sigma (\{ml\}) = ml$, otherwise, $\sigma$ is undefined.
The inference rules showed in Table~\ref{rules} can only be applied if the
unification of their labels is defined (where $* - 1 = *$). Note that for GEN1
and GEN3, if the modal clauses occur at the modal level $ml$, then the literal
clause occurs at the next modal level, $ml + 1$.

\begin{definition}
    Let $\Clauses$ be a set of clauses in \snf{$ml$}. A \emph{derivation} from
    $\Clauses$ is a sequence of sets $\Clauses_0, \Clauses_1, \ldots$ where
    $\Clauses_0 = \Clauses$ and, for each $i > 0$, $\Clauses_{i+1} = \Clauses_i
    \cup \{D\}$, where $D$ is the resolvent obtained from $\Clauses_i$ by an
    application of either LRES, MRES, GEN1, GEN2 or GEN3. It is also required
    that $D$ is in simplified form, $D \notin \Clauses_i$ and that $D$ is not a
    tautology. A \emph{local refutation} for $\Clauses$ is a finite derivation
    that contains the empty clause at the initial modal level, that is $0:
    false$. Meanwhile, a \emph{global refutation} for
    $\Clauses$ is a finite derivation that contains the empty clause at any
    modal level~\cite{nalon2015modal}.
\end{definition}

\input{tex/rules}

\begin{example}%
    \label{ex:calcsat}
    Consider the set of clauses in \snf{$ml$} of Example~\ref{ex:snf}, generated
    for $\formula = \nec{}(a \then b) \then (\nec{} a \then \nec{}b)$.

    Figure~\ref{tab:calcsat} shows a derivation from the eight
    clauses obtained by the transformation, once that no other rule can be
    applied and no refutation is generated. Thus, proving that, indeed,
    $\formula$ is a satisfiable formula, as expected.

    \begin{figure}[h!]%
        \centering%
        \begin{tabular}{rlrll}
            1. & $0 : t_0$                        & 8. & $1 : \neg t_4 \lor \neg b$   & \\
            2. & $0 : \neg t_0 \lor t_2 \lor t_1$ & 9.  & $0 : t_2 \lor t_1$          & [LRES, 1, 2, $t_0$]\\ 
            3. & $0 : \neg t_1 \lor t_5 \lor t_3$ & 10. & $0 : t_2 \lor t_5 \lor t_3$ & [LRES, 9, 3, $t_1$]\\ 
            4. & $0 : t_2 \then \pos {}t_4$       & 11. & $0 : \neg t_2$              & [GEN1, 4, 7, 8, $t_4$]\\
            5. & $0 : t_5 \then \pos{} \neg a$    & 12. & $0 : t_5 \lor t_3$          & [LRES, 10, 11, $t_2$]\\ 
            6. & $0 : t_3 \then \nec{} b$         & 13. & $0 : \neg t_3$              & [GEN3, 6, 5, 8, $b, a$]\\
            7. & $1 : \neg t_4 \lor a$            & 14. & $0 : t_5$                   & [LRES, 13, 14, $t_3$] \\
       \end{tabular}%
        \caption{Satisfiability proof of the formula $\formula$ from Example~\ref{ex:snf}}%
        \label{tab:calcsat}
    \end{figure}
\end{example}

\begin{example}
    Adapted from~\cite{Areces:1999:PRR,nalon2015modal}. Consider the clauses in
    Figure~\ref{tab:calcunsat}. Clauses 1 and 2 state that a dog is either
    male or female. Clauses 3 and 4, only serving the purpose of illustration,
    say that big dogs have puppies with brown fur. The particular situation
    of Toto, denoted here by $t_0$, is given in the following clauses: Clauses
    5, 6 and 7 say that Toto's puppies are all female and big. Clauses 8 and 9
    say that a grandpuppy of Toto doesn't have brown fur. We want to prove that
    Toto has a male puppy, which appears negated in Clause 10. The refutation is
    given by Figure~\ref{tab:calcunsat}. 

    \begin{figure}[h!]%
        \centering%
        \begin{tabular}{rlrll}
            1.&$* : \mathit{female} \lor \mathit{male}$           & 9. &$1 : t_3 \then \pos{p} \neg \mathit{brown}$            & \\
            2.&$* : \neg \mathit{female} \lor \neg \mathit{male}$ & 10.&$0 : t_0 \then \nec{p} \neg \mathit{male}$             & \\ 
            3.&$* : \neg \mathit{big} \lor t_1$                   & 11.&$1 : \neg t_1 \lor \neg t_3$                           & [MRES, 9, 4, $\mathit{brown}$]\\
            4.&$* : t_1 \then \nec{p} \mathit{brown}$             & 12.&$1 : \neg \mathit{big} \lor \neg t_3$                  & [LRES, 11, 3, $t_1$]\\
            5.&$0 : t_0$                                          & 13.&$1 : \neg t_3 \lor \neg t_2 \lor \neg \mathit{female}$ & [LRES, 7, 12, $\mathit{big}$]\\
            6.&$0 : t_0 \then \nec{p} t_2$                        & 14.&$1 : \mathit{male} \lor \neg t_3 \lor \neg t_2$        & [LRES, 13, 1, $\mathit{big}$]\\
            7.&$1 : \neg t_2 \lor \neg \mathit{female} \lor \mathit{big}$ & 15.&$0 : \neg t_0$ & [GEN1, 10, 6, 8, 14, $\mathit{male},t_2,t_3$]\\
            8.&$0 : t_0 \then \pos{p} t_3$                        & 16.&$0 : \cfalse$ & [LRES, 15, 5, $t_0$]\\
       \end{tabular}%
        \caption{An example of refutation}%
        \label{tab:calcunsat}
    \end{figure}
\end{example}

The proofs for termination, soundness and completeness of this calculus can be
found in~\cite{nalon2015modal}.

\subsection{\ksp}
In this section, we briefly introduce \ksp, the theorem prover presented
in~\cite{Nalon2016} for the basic multimodal logic \system{K}{n}{}, which
implements a variation of the set of support strategy~\cite{wos1965efficiency}
for the modal resolution-based calculus described in Section~\ref{sec:calculus}.

\ksp\ was designed to support experimentation with different combinations of
refinements of its basic calculus. Refinements and options for processing and
preprocessing the input are coded as independently as possible in order to allow
for the easy addition and testing of new features. Although, this may not lead
to optimal performance, since techniques need to be applied one after another,
whereas most tools would apply them all together. On the other hand, this helps
to evaluate how the different options independently contribute to achieve
efficiency~\cite{Nalon2016}. 

The results showed in~\cite{Nalon2016} indicates that \ksp\ works well on
problems with high modal depth where the separation of modal layers can be
exploited to improve the efficiency of reasoning. Although, as with all provers
that provide a variety of strategies and optimizations, to get the best
performance for a particular formula or class or formulae, it is important to
choose the right strategy and optimizations. \ksp\ leaves this choice to the
user. The same applies to the transformation to the layered normal form.

According to~\cite{Nalon2016}, \ksp\ performs well if the set of propositional
symbols are uniformly distributed over the modal levels. However, when there is
a high number of propositional symbols in just one particular level, the
performance deteriorates. One reason is that the specific normal form we use
always generates satisfiable sets of propositional clauses. As resolution relies
on saturation, this can be very time consuming. We are currently investigating
the use of other tools in order to speed up the saturation process.

Next chapter presents 
