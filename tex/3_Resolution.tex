%\section{}
Resolution appeared in the early 1960's through investigations on performance
improvements of refutational systems based on the \emph{Herbrand's Theorem}, which
allows a kind of reduction of first-order logic to propositional
logic~\cite{casanova}. In particular, Prawitz' studies of such systems brought
back the concept of unification. J.\ A.\ Robinson incorporated this concept on a
refutational system, creating what was later known as
resolution~\cite{Robinson65}. 

Resolution relies on saturation. A saturation-based theorem proving is usually
characterized by a process in which new formulae are derived from given
ones by thorough application of specified inference rules, with the ultimate
goal of obtaining a contradiction. In addition, the current set of formulae is
analyzed to identify the most promising inference rules to be applied next and
to eliminate redundancies~\cite{bachmair2001resolution}.

Numerous resolution systems have been proposed in the literature. The standard
system has only one inference rule~\cite{bachmair2001resolution}, showed in
Equation~\ref{eq:res}, that takes two \emph{clauses} with literals that form a
complementary pair and generates a \emph{resolvent}, where each clause, denoted
by $\clause$, is a disjunction of literals. 

\begin{equation}
\label{eq:res}
 \begin{array}{lc}
     \mbox{[RES]} & \clause_i \lor l \qquad \neg l \lor \clause_j\\  \cline{2-2}
     & \clause_i \lor \clause_j
\end{array}
\end{equation}
where $\clause_i$ and $\clause_j$ are possibly empty clauses, $l$ is a literal
and $\clause_i \lor \clause_j$ is the resolvent.

We use the constant $\cfalse$ to denote the \emph{empty clause},
i.e., the clause that contains no literals. Due to the associativity and
commutativity properties of disjunction, one may see a clause as a set of
literals. In this work we might abuse of set notation, writing $l \in \clause$,
when $l$ is a literal of $\clause$, and $\clause_i \subseteq \clause_j$, when
all literals in $\clause_i$ are also literals in $\clause_j$.

A clause set is said to be \emph{saturated} when relevant information can not be
generated, regardless of the rule that is applied~\cite{dershowitz2003abstract}.
Saturation, up to redundancy, of the initial clause set is a quite useful
criteria when we are thinking in terms of
% cite reference to termination 
termination proof and completeness proof~\cite{fitting} of a calculus.

% be specific %
Most of the systems based on the rule of Equation~\ref{eq:res} work exclusively
with clauses in a specific normal form. Resolution, as proposed by Robinson, is
a refutationally complete theorem proving method for first order
logic~\cite{Robinson65}.  Therefore, to show that a formula \formula~is valid,
$\neg \formula$ is translated into a normal form, then the inference rule is
applied until either no new resolvents can be generated or a contradiction is
obtained. This means that the search for a contradiction proceeds by saturating
the given clause set, exhaustively applying the inference
rule~\cite{bachmair2001resolution}. The contradiction implies that $\neg
\formula$ is unsatisfiable and hence, that \formula~is valid. 

Resolution-based provers are widely implemented and tested. Besides reliable
implementations, we can also profit from several complete strategies which can
be extended to deal with modal resolution~\cite{journals/jal/NalonD07}. Such
provers for multimodal logics require pruning of the search space for a proof in
order to deal with the inherent intractability of the satisfiability problem for
such logics. In~\cite{nalon2015modal}, Nalon et.\ al.\ present a clausal
modal-layered resolution calculus for \system{K}{n}{}, which divides the clause
set according to the modal depth at which each clause occurs. This calculus is
introduced in Section~\ref{sec:calculus}.

\section{Clausal Resolution}

Clausal resolution is a simple and adaptable proof system for classical logics.
It was proposed by Robinson in 1965~\cite{Robinson65}, and was claimed to be
suitable to be performed by a computer, as, for propositional logic, it has only
one inference rule that is applied. Robinson emphasizes that, from the
theoretical point of view, an inference rule need only to be sound and
effective, that is, it allows only logical consequences of premisses to be
deduced and it must be algorithmically decidable whether an alleged application
of the rule is indeed an application of it.

The single inference rule of this system of logic entails the \emph{resolution
principle}, namely: \emph{From any two clauses} $\clause_i$ \emph{and}
$\clause_j$ \emph{which contain a complementary pair of literals, one may infer
a resolvent of} $\clause_i$ \emph{and} $\clause_j$~\cite{Robinson65}.   

In his paper, Robinson presents a formulation of first-order logic designed to
be used as the basic theoretical instrument of the proposed computer
theorem-proving program. For the purpose of this work, we are only interested in
the calculus for propositional logic. Therefore, we will neither discuss the theory
behind the Herbrand's Theorem nor the definition of the unification procedure,
but, if curious, the reader can refer to~\cite{Robinson65} for more details.

In the sense of this last remark, the only representational formalism needed is
propositional logic. As resolution has only the RES rule, a proof consists of
repeated application of this rule to the propositional clauses. These
applications are sufficient to derive an empty clause if and only if the initial
formula is unsatisfiable~\cite{satchapter}.

\begin{example}%
\label{ex:res}
    Consider the set of clauses $\Clauses = \{(\neg p \lor q), (\neg p \lor r),
    (\neg r \lor q), (\neg q \lor r), \neg r, p\}$. Table~\ref{tab:res} shows an
    example of derivation of the empty clause for $\Clauses$, proving that this
    set is unsatisfiable. 

    \begin{table}%
    \caption{Derivation of $\Clauses$ in Example~\ref{ex:res}}
        \centering
        \begin{tabular}{rlll}
            1. & $\neg p \lor q$ & & \\
            2. & $\neg p \lor r$ & & \\
            3. & $\neg r \lor q$ & & \\
            4. & $\neg q \lor r$ & & \\
            5. & $\neg r$ & & \\
            6. & $p$ & & \\
            7. & $\neg p \lor q$ & [RES,3,2] & $= 1$\\
            8. & $\neg p \lor r$ & [RES,4,1] & $= 2$\\
            9. & $\neg q \lor q$ & [RES,4,3] & $= \ctrue$\\
            10.&  $\neg r \lor r$ & [RES,4,3] & $= \ctrue$\\
            11.&  $\neg p$ & [RES,5,2] & \\
            12.&  $\neg q$ & [RES,5,4] & \\
            13.&  $q$ & [RES,6,1] & \\
            14.&  $r$ & [RES,6,2] & \\
            15.&  $\cfalse$ & [RES,11,6] & contradiction\\
        \end{tabular}%
    \label{tab:res}
    \end{table}

    Despite its simplicity, unrestricted resolution is hard to implement
    efficiently due to the difficulty of finding good choices of clauses to
    resolve~\cite{satchapter}. As one can see in this example, natural choices
    typically imply huge storage requirements. Even with such a short set of
    clauses (only 6 initially), the application of the resolution rule, without
    any restriction, yields the generation of tautologies, Clauses 9 and 10, and
    repeated clauses, Clauses 7 and 8. That is, useless information is generated
    and stored until the contradiction can be found. 
\end{example}

Robinson established two principles, namely \emph{purity principle} and
\emph{subsumption principle}, to discuss the question of developing efficient
resolution systems. A refutation system based on resolution incorporating the
first principle tends to derive a smaller number of clauses.  On the other hand,
the incorporation of the second principle helps to increase the rate of which a
contradiction is derived~\cite{Robinson65}. Such principles are called
\emph{search principles}.  A third search principle is presented in terms of
replacement using the subsumption principle, named, \emph{self-subsumption}. 

\begin{definition}
    If $\Clauses$ is any finite set of clauses, $\clause$ is a clause in
    $\Clauses$ and $l$ a literal in $\clause$ with the property that no literal
    in any other clause in $\Clauses$ form a complementary pair with $l$, then
    $l$ is said to be \emph{pure} in $\Clauses$.
\end{definition}

The purity principle is then based on Theorem~\ref{theo:pure}.

\begin{theorem}%
    \label{theo:pure}
    If $\Clauses$ is any finite set of clauses, and $l \in \clause \in \Clauses$
    is a pure literal in $\Clauses$, then $\Clauses$ is satisfiable if and only
    if $\Clauses - \{\clause\}$ is satisfiable.
\end{theorem}

\begin{definition}
    If $\clause_i$ and $\clause_j$ are two distinct nonempty clauses, we say
    that $\clause_i$ \emph{subsumes} $\clause_j$ in the case that $\clause_i
    \subseteq \clause_j$. 
\end{definition}

Theorem~\ref{theo:subs} establishes the basic property of subsumption.

\begin{theorem}%
    \label{theo:subs}
    If $\Clauses$ is any finite set of clauses, and $\clause_j$ is any clause
    in $\Clauses$ which is subsumed by some clause in $\Clauses -
    \{\clause_j\}$, then $\Clauses$ is satisfiable if and only if $\Clauses -
    \{\clause_j\}$ is satisfiable.
\end{theorem}

Theorems~\ref{theo:pure} and~\ref{theo:subs} are both proved in~\cite{Robinson65}.

A particularly useful application of the subsumption principle is the following:
suppose a resolvent $\clause_R$ of $\clause_i$ and $\clause_j$ subsumes
$\clause_i$, then in adding $\clause_R$ as a result of resolving $\clause_i$ and
$\clause_j$, we may simultaneously delete, by the subsumption principle,
$\clause_i$. This combined operation entails the replacement of $\clause_i$ by
$\clause_R$; accordingly this third principle is named as the
self-subsumption principle.

The application, to a finite set $\Clauses$ of clauses, of any of the three
search principles described, produces a set $\Clauses'$ which either has fewer
clauses than $\Clauses$ or has the same number, but with one or more shorter
clauses~\cite{Robinson65}. 

\begin{example}
    Let $\Clauses$ be the set of clauses showed in Table~\ref{tab:resa}. Prior
    to the thorough application of the RES rule, one may search for
    opportunities to apply the search principles, in order to reduce the
    number of clauses and increase the rate of which a contradiction is derived.

    In this example, the third clause can be eliminated from the set of clauses
    through an application of the purity principle, as expressed in
    Table~\ref{tab:resb}, once there is no other clause that has the
    complementary pair of the literal $u$. 
    Furthermore, as the Clause 5 subsumes the Clause 4, this last one can also
    be eliminated from the set of clauses, leaving only the clauses in
    Table~\ref{tab:resc}.
    The application of RES to Clauses 1 and 2 generates the resolvent
    $\neg q$, which subsumes both clauses, hence, by the self-subsumption principle,
    both may be replaced by the Clause 7, as showed in Table~\ref{tab:resd}.
    Finally, the application of RES to the Clauses 5 and 7, generates the Clause
    8 as a resolvent, and then resolving this one with the Clause 6 will
    generate the empty clause, thus, a contradiction. 

    Applying the search principles allowed us to go from a set of six clauses
    with four literals to a set of four clauses with only two.

    \begin{table}
        \caption{Derivation schemes for Example~\ref{ex:principles}}
        \centering
       \begin{subtable}{.20\textwidth}
           \caption{Initial clauses}
           \begin{tabular}{rl}
               1. & $\neg q \lor \neg r$ \\
               2. & $\neg q \lor r$ \\
               3. & $u \lor \neg p$ \\
               4. & $\neg p \lor q \lor \neg r$ \\
               5. & $\neg p \lor q$ \\
               6. & $p$
           \end{tabular}%
           \label{tab:resa}
       \end{subtable} 
       \begin{subtable}{.21\textwidth}
           \caption{Purity principle}
           \begin{tabular}{rl}
               1. & $\neg q \lor \neg r$ \\
               2. & $\neg q \lor r$ \\
               4. & $\neg p \lor q \lor \neg r$ \\
               5. & $\neg p \lor q$ \\
               6. & $p$ \\
                  & 
           \end{tabular}%
           \label{tab:resb}
       \end{subtable} 
       \begin{subtable}{.19\textwidth}
           \caption{Subsumption}
           \begin{tabular}{rl}
               1. & $\neg q \lor \neg r$ \\
               2. & $\neg q \lor r$ \\
               5. & $\neg p \lor q$ \\
               6. & $p$ \\
                  & \\
                  &
           \end{tabular}%
           \label{tab:resc}
       \end{subtable} 
       \begin{subtable}{.24\textwidth}
           \caption{Replacement}
           \begin{tabular}{rll}
               5. & $\neg p \lor q$ \\
               6. & $p$ \\
               7. & $\neg q$ & [RES,1,2] \\
               8. & $\neg p$ & [RES,5,7] \\
               9.& $\cfalse$ & [RES,6,8] \\
                  &
           \end{tabular}%
           \label{tab:resd}
       \end{subtable} 
    \end{table}%
\label{ex:principles}
\end{example}

There are further principles of the same general sort, possibly less simple than
the ones presented earlier, which Robinson considers to be merely a brief view
of the possible approaches to the efficiency problem of resolution systems.
Details can be found in~\cite{Robinson65}.

\section{Modal-Layered Resolution Calculus for \system{K}{n}{}}%
\label{sec:calculus}

The calculus presented in this section requires a translation into a more
expressive modal language, where labels are used to express semantic properties
of a formula. This transformation is presented in Section~\ref{sec:snf}.
Furthermore, this calculus makes use of labelled resolution in order to avoid
unnecessary applications of the inference rules~\cite{nalon2015modal}. For
instance, we do not apply resolution to clauses at different modal levels, since
they are not, in fact, contradictory.

\subsection{Separated Normal Form with Modal Levels}%
\label{sec:snf}

Formulae in \system{K}{n}{} can be transformed into a layered normal form called
\emph{Separated Normal Form with Modal Levels}, denoted by \snf{$ml$}, proposed
in~\cite{journals/jal/NalonD07}, hence, all the definitions in this section are
taken from~\cite{journals/jal/NalonD07}. A formula in \snf{$ml$} is a
conjunction of \emph{clauses} where the modal level in which they occur is made
explicit in the syntax as a label.

We write $ml: \formula$ to denote that \formula~occurs at modal level $ml\in
\Nat \cup \{*\}$. By $*: \formula$ we mean that \formula~is true at
all modal levels. Formally, let $\wffml$ denote the set of formulae with
the modal level annotation, $ml : \formula$, such that $ml \in \Nat \cup \{*\}$
and $\formula \in \wff$. Let $\Model^* = (W, \st_0, R_1, \ldots, R_n, R_*, \pi)$
be a tree-like model and take $\formula \in \wff$. 

\begin{definition}
Satisfiability of labelled formulae is given by:

\begin{enumerate}
    \item $\Model^* \models_L ml : \formula$ if, and only if, for all worlds
        $\st \in W$ such that $depth(\st) = ml$, we have
        \sat{\Model^*}{\st}{\formula} 
    \item $\Model^* \models_L * : \formula$ if, and only if, $\Model^* \models
        \nec{*} \formula$
\end{enumerate}
    
\end{definition}

Clauses in \snf{$ml$} are defined as follows.

\begin{definition}
    Clauses in \snf{$ml$} are in one of the following forms:
    \begin{enumerate}
        \item Literal clause $\ \ \quad \qquad ml : \bigvee^r_{b=1} l_b$
        \item Positive $a$-clause $\ \qquad ml : l' \then \nec{a} l$
        \item Negative $a$-clause $\qquad ml : l' \then \pos{a} l$
    \end{enumerate}
    where $r, b \in \Nat, ml \in \Nat \cup \{*\}$, $l, l', l_b \in
    \Literals$ and $\agent \in \Agents = \{1, \ldots, n\}$.
\end{definition}

Positive and negative $a$-clauses are together known as \emph{modal
$a$-clauses}, the index $a$ can be omitted if it is clear from the context.

The transformation of a formula $\formula \in \wff$ into \snf{$ml$} is achieved
by first transforming $\formula$ into its \emph{Negation Normal Form}, and then,
recursively applying rewriting and renaming~\cite{plaisted1986structure}.

\begin{definition}
    Let $\formula \in \wff$. We say that $\formula$ is in Negation Normal Form (NNF) if
    it contains only the operators $\neg, \lor, \land, \nec{a}$ and $\pos{a}$. Also,
    only propositions are allowed in the scope of negations.
\end{definition}

Let $\formula$ be a formula and $t$ a propositional symbol not occurring in
$\formula$. The translation of $\formula$ is given by $0 : t \land \rho(0 : t
\then \formula)$ --- for global satisfiability, the translation is given by $* :
t \land \rho(* : t \then \formula)$ --- where $\rho$ is the \emph{translation
function} defined below. We refer to clauses of the form $0 : D$, for a
disjunction of literals $D$, as \emph{initial clauses}. 

\begin{definition}
    The translation function $\rho : \wffml \longrightarrow \wffml$ is defined
    as follows:
        \begin{align*}
            \rho(ml : t \then \formula \land \psi) & = \rho(ml : t \then \formula) \land \rho(ml : t \then \psi) \\
            \rho(ml : t \then \nec{a} \formula) & = (ml : t \then \nec{a} \formula) \text{, if \formula\ is a literal}\\
                                                & = (ml : t \then \nec{a} t') \land \rho(ml+1 : t' \then \formula) \text{, otherwise}\\
            \rho(ml : t \then \pos{a} \formula) & = (ml : t \then \pos{a} \formula) \text{, if \formula\ is a literal}\\
                                                & = (ml : t \then \pos{a} t') \land \rho(ml+1 : t' \then \formula) \text{, otherwise}\\
            \rho(ml : t \then \formula \lor \psi) & = (ml : \neg t \lor \formula
            \lor \psi) \text{, if $\psi$ is a disjunction of literals}\\
                                                  & = \rho(ml : t \then \formula \lor t') \land \rho(ml : t' \then \psi) \text{, otherwise}
        \end{align*}
        Where $t, t' \in \Literals$, $\formula, \psi \in \wff$, $ml \in
        \Nat \cup \{*\}$ and $r, b \in \Nat$.
\end{definition}

As the conjunction operator is commutative, associative and idempotent, we will
commonly refer to a formula in \snf{$ml$} as a set of clauses.

\begin{example}%
    \label{ex:snf}
    Let $\formula$ be the formula $\nec{}(a \then b) \then (\nec{}a \then \nec{} b)$.
    We show how to translate $\formula$ into its normal form, considering the local
    satisfiability problem.

    First, we anchor the NNF of $\formula$ to the initial state:
    \begin{equation}
        \label{eq:initial}
        0 : t_0 \land \rho(0 : t_0 \then \pos{} (a \land \neg b) \lor \pos{} \neg a \lor \nec{} b)
    \end{equation}

    The Equation~\ref{eq:initial} is used to anchor the meaning of $\formula$ to
    the initial state, where the formula is evaluated. The function $\rho$
    proceeds with the translation, replacing complex formulae inside the
    scope of the $\nec{}$ and $\pos{}$ operators, by means of renaming. 

    So the translation proceeds as follows:
    \begin{align*}
        &\rho(0 : t_0 \then \pos{} (a \land \neg b) \lor \pos{} \neg a \lor \nec{} b) \\
        &= \rho(0: t_0 \then \pos{} (a \land \neg b) \lor t_1) \land \rho(0: t_1 \then \pos{} \neg a \lor \nec{} b) \\
        &= \rho(0: t_0 \then t_2 \lor t_1) \land \rho(0 : t_2 \then \pos {}(a \land \neg b)) \land \rho(0: t_1 \then \pos{} \neg a \lor t_3) \land \rho(0: t_3 \then \nec{} b) \\
        &= (0: \neg t_0 \lor t_2 \lor t_1) \land (0 : t_2 \then \pos {}t_4) \land \rho(1 : t_4 \then a \land \neg b) \land \rho(0: t_1 \then t_5 \lor t_3) \land \\
        &\ (0 : t_5 \then \pos{} \neg a) \land (0: t_3 \then \nec{} b) \\
        &= (0: \neg t_0 \lor t_2 \lor t_1) \land (0 : t_2 \then \pos {}t_4)
        \land \rho(1 : t_4 \then a) \land \rho(1 : t_4 \then \neg b) \land \\ 
        &\ (0: \neg t_1 \lor t_5 \lor t_3) \land (0 : t_5 \then \pos{} \neg a) \land (0: t_3 \then \nec{} b) \\
        &= (0: \neg t_0 \lor t_2 \lor t_1) \land (0 : t_2 \then \pos {}t_4)
        \land (1 : \neg t_4 \lor a) \land (1 : \neg t_4 \lor \neg b) \land \\ 
        &\ (0: \neg t_1 \lor t_5 \lor t_3) \land (0 : t_5 \then \pos{} \neg a) \land (0: t_3 \then \nec{} b) \\
    \end{align*}

    The translation leads us with seven clauses, two of them at the subsequent
    modal level ($1 : \neg t_4 \lor a$ and $1 : \neg t_4 \lor \neg b$). Note
    that, from the five clauses at the initial modal level, we have two literal
    clauses ($0: \neg t_0 \lor t_2 \lor t_1$ and $0: \neg t_1 \lor t_5 \lor
    t_3$), two negative ($0 : t_2 \then \pos {}t_4$ and $0 : t_5 \then \pos{}
    \neg a$) and one positive clause ($0: t_3 \then \nec{} b$).
\end{example}

The set of clauses obtained by translating the formula $\formula$ into
\snf{$ml$}, from Example~\ref{ex:snf}, must be locally satisfiable if, and only
if, $\formula$ is locally satisfiable. The next lemma, taken
from~\cite{nalon2015modal}, shows that the transformation into \snf{$ml$}
preserves satisfiability.

\begin{lemma}
    Let $\formula \in \wff$ be a formula and let $t$ be a propositional symbol
    not occurring in $\formula$. Then: 
    \begin{enumerate}
        \item[$(i)$] $\formula$ is locally satisfiable if, and only if, $0 : t \land \rho(0 : t \then \formula)$ is satisfiable;
        \item[$(ii)$] $\formula$ is globally satisfiable if, and only if, $* : t \land \rho(* : t \then \formula)$ is satisfiable.
    \end{enumerate}
\end{lemma}

\subsection{Calculus}

The motivation for the use of this labelled clausal normal form in a calculus is
that inference rules can then be guided by the semantic information given by the
labels and applied to smaller sets of clauses, reducing the number of
unnecessary applications, and therefore improving the efficiency of the proof
procedure~\cite{Nalon2016}. 

The modal-layered resolution calculus, proposed by Nalon et.\ al.\
in~\cite{nalon2015modal}, comprises a set of inference rules, given in
Table~\ref{rules}, for dealing with propositional and modal reasoning. In the
following, we denote by $\sigma$ the result of unifying the labels in the
premises for each rule.  Formally, unification is given by a function $ \sigma :
\mathscr{P}(\Nat \cup \{*\}) \longrightarrow \Nat \cup \{*\}$, where $\sigma
(\{ml, *\}) = ml$ and $\sigma (\{ml\}) = ml$, otherwise, $\sigma$ is undefined.
The inference rules showed in Table~\ref{rules} can only be applied if the
unification of their labels is defined (where $* - 1 = *$). Note that for GEN1
and GEN3, if the modal clauses occur at the modal level $ml$, then the literal
clause occurs at the next modal level, $ml + 1$.

\begin{definition}
    Let $\Clauses$ be a set of clauses in \snf{$ml$}. A \emph{derivation} from
    $\Clauses$ is a sequence of sets $\Clauses_0, \Clauses_1, \ldots$ where
    $\Clauses_0 = \Clauses$ and, for each $i > 0$, $\Clauses_{i+1} = \Clauses_i
    \cup \{D\}$, where $D$ is the resolvent obtained from $\Clauses_i$ by an
    application of either LRES, MRES, GEN1, GEN2 or GEN3. It is also required
    that $D$ is in simplified form, $D \notin \Clauses_i$ and that $D$ is not a
    tautology. A \emph{local refutation} for $\Clauses$ is a finite derivation
    that contains the empty clause at the initial modal level, or $0:
    false$. Meanwhile, a \emph{global refutation} for
    $\Clauses$ is a finite derivation that contains the empty clause at any
    modal level~\cite{nalon2015modal}.
\end{definition}

\input{tex/rules}

\begin{example}
    Consider the set of clauses in \snf{$ml$} of Example~\ref{ex:snf}, generated for
    $\formula = \nec{}(a \then b) \then (\nec{} a \then \nec{}b)$. 

\end{example}

\begin{example}
    
\end{example}

The proofs for termination, soundness and completeness of this calculus can be
found in~\cite{nalon2015modal}.

\subsection{\ksp}
In this section, we briefly introduce \ksp, the theorem prover presented
in~\cite{Nalon2016} for the basic multimodal logic \system{K}{n}{}, which
implements a variation of the set of support strategy~\cite{wos1965efficiency}
for the modal resolution-based calculus described in Section~\ref{sec:calculus}.

\ksp\ was designed to support experimentation with different combinations of
refinements of its basic calculus. Refinements and options for processing and
preprocessing the input are coded as independently as possible in order to allow
for the easy addition and testing of new features, even though this may not lead
to optimal performance, since techniques need to be applied one after another,
whereas most tools would apply them all together, but this helps to evaluate how
the different options independently contribute to achieve
efficiency~\cite{Nalon2016}. 

The results showed in~\cite{Nalon2016} indicates that \ksp\ works well on
problems with high modal depth where the separation of modal layers can be
exploited to improve the efficiency of reasoning. Although, as with all provers
that provide a variety of strategies and optimizations, to get the best
performance for a particular formula or class or formulae, it is important to
choose the right strategy and optimizations. \ksp\ leaves this choice to the
user. The same applies to the transformation to the layered normal form.

\ksp\ performs well if the set of propositional symbols are uniformly distributed
over the modal levels. However, when there is a high number of propositional
symbols in just one particular level, the performance deteriorates. One reason
is that the specific normal form we use always generates satisfiable sets of
propositional clauses (clauses without modal operators). As resolution relies on
saturation, this can be very time consuming. We are currently investigating the
use of other tools in order to speed up the saturation process.
